{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Yox0gG1DsF"
   },
   "source": [
    "Homework 5: Neural Language Models  (& ðŸŽƒ SpOoKy ðŸ‘» authors ðŸ§Ÿ data) - Task 4\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: Harishraj Udaya Bhaskar(6120 Student) (Write these in every notebook you submit. For each partner, write down whether you are a 4120 or a 6120 student.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxWlOU9k1DsQ"
   },
   "source": [
    "Task 4: Compare your generated sentences (15 points)\n",
    "----\n",
    "\n",
    "In this task, you'll analyze one of the files that you produced in Task 3. You'll need to compare against the corresponding file that we have provided for you that was generated from the vanilla n-gram language model.\n",
    "\n",
    "Choose *__one__* of the following two options.\n",
    "\n",
    "Option 1: Evaluate the generated words of *character*-based models\n",
    "---\n",
    "\n",
    "Your job for this option is to programmatically measure two things:\n",
    "1. the percentage of words produced by each model that are valid english words.\n",
    "2. the percentage of words produced by each model that are valid english words *and* were not seen at train time.\n",
    "\n",
    "For this task, a word is defined as \"characters between _ \" or \"characters between spaces\" (if you replaced your underscores with spaces when you printed out your new sentences).\n",
    "\n",
    "\n",
    "Make sure to turn in any necessary supporting files along with your submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your imports here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How did you determine what a valid english word is? __YOUR ANSWER HERE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Gather the sequences of characters that are determined not to be words. Sampling at minimum 100 of these sequences, how many of them *should have* been counted as words in your opinion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more code here, as needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit two csv files alongside this notebook: `valid_words_lms.csv` and `invalid_words_lms.csv`. Both files should have __two__ columns: `model`, `sequence`. `model` will have the value `neural` or `vanilla`. `sequence` will be the corresponding sequence of characters. `valid_words_lms.csv` should contain all sequences from both models you determined to be valid words. `invalid_words_lms.csv` will have all sequences from both models you programatically determined to be invalid words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "316H0xSh1DsQ"
   },
   "source": [
    "Option 2: Evaluate the generated sentences of *word*-based models\n",
    "----\n",
    "\n",
    "Your job for this option is to measure the quality of your generated sentences for word-based models. For this option you *must* survey at least 3 people who are __not__ in this course. They need to speak and read the language that you are evaluating, but they need not be native speakers.\n",
    "\n",
    "You will evaluate the quality of the generated sentences in the following way:\n",
    "1. Generate 20 sentences from your neural model.\n",
    "2. Using the same level of n-gram, pair these sentences with provided sentences from the vanilla n-gram model.\n",
    "\n",
    "Next, build a survey. For each pair of (neural LM sentence, vanilla n-ngram LM sentence), you'll ask the survey taker two binary selection questions:\n",
    "1. which sentence is more grammatical?\n",
    "2. which sentence makes more sense, semantically (in meaning)?\n",
    "3. Which sentence do you prefer?\n",
    "\n",
    "\n",
    "Finally, you'll evaluate your survey results. Calculate the following:\n",
    "1. What percentage of neural vs. vanilla n-gram LM sentences were preferred, separated along each of the three dimensions?\n",
    "2. What is [Krippendorff's alpha](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha) for your survey data? \n",
    "\n",
    "You are welcome to use a pre-built python implmenetation of the Krippendorff's alpha calculation, such as [this one](https://pypi.org/project/krippendorff/). Krippendorff's alpha is one way to measure interannotator agreement â€” the extent to which your survey respondants agree with one another.\n",
    "\n",
    "You will submit your survey data alongside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am curious of pretty the <s> unknown , <s> back </s> <s> beyond will is child companion <s> countenance </s> <s> since <s> confusion a\n",
      "is this why he was <s> remains appetite and when for else individual </s> in through difference have <s> low </s> <s> mountains and idea for magic my those in secret he\n",
      "is this us , . ' through strange not head </s> before he <s> calm when ? received he edge i well and when for read castle to had slightest by then\n",
      "i am curious of pretty the <s> unknown , <s> back </s> <s> beyond will is child companion <s> countenance </s> <s> since <s> confusion a\n",
      "is this why he was <s> remains appetite and when for else individual </s> in through difference have <s> low </s> <s> mountains and idea for magic my those in secret he\n",
      "is this us , . ' through strange not head </s> before he <s> calm when ? received he edge i well and when for read castle to had slightest by then\n",
      "i am curious of where is closer had and him note one , ? and had your have whose in hand author , . in degree </s> in through what 's remained\n",
      "i am curious of is where city times taken , all every of st. us should of he <s> fire </s> as river had whispers . soon small </s> old he his\n",
      "is this why he was where is though </s> <s> explanation after </s> <s> the more even big </s> yourself that with his that which <s> any before the at have .\n",
      "is this why he was is where <s> time london occupied </s> arkham the gentle <s> any food <s> </s> <s> even length <s> cut spaces </s> <s> </s> <s> time <s>\n",
      "is this where is all when but is away i did a fashion not it <s> so </s> <s> amidst his their incidents not even head upon <s> river </s> <s> </s>\n",
      "is this is where has but time <s> beyond </s> <s> mind three the <s> creatures <s> mr. </s> <s> von plains , mystic no tale <s> language him be hours important\n",
      "where is this absence our through voice own need of relieved bay , village be idea as calling her </s> seen had . earth his that abaout <s> front of thorough ,\n",
      "where is why of means , design </s> of high never <s> seen </s> <s> expression </s> <s> vicinity requisite , <s> given her <s> staring </s> <s> de </s> <s> de\n",
      "is where this ordinary <s> instead </s> of artist might , <s> </s> <s> </s> <s> beyond that is is one she at <s> suffered </s> <s> built were of it all\n",
      "is where why <s> right </s> hideously by from sought the <s> direction </s> in face the <s> good </s> <s> 's that and had is sake the who chamber captain did\n",
      "is is this work he <s> simply </s> our books , </s> in through illustrious coffin a <s> ghost </s> carpet have boy fear <s> </s> <s> desires had paused as fully\n",
      "is is why by of who out upon i </s> <s> desert had works by the in gentleman </s> sides my little utter the sorrow was <s> hence </s> <s> various had\n",
      "where is curious the left pointed blind <s> </s> <s> always over <s> evening not <s> sorrow were for her up the house how and how to a of or sad moved\n",
      "where is he more heart and such for but consider the left man rose and up on walked far this i and multitude could the true ; greatly ; and when over\n"
     ]
    }
   ],
   "source": [
    "#Printing the Nueral net generated sentences\n",
    "file_path = 'word_sentences.txt'\n",
    "line_count = 0\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Display only 20 lines\n",
    "        if line_count < 20:\n",
    "            print(line.strip())  # strip() removes newline characters\n",
    "            line_count += 1\n",
    "        else:\n",
    "            break  # Stop reading after 20 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i know not why .\n",
      "idris sat at a post worthy of greek tragedy .\n",
      "still thou canst listen to me a treasure of dust ; and though the animal functions uninterruptedly , but i was not irregular in action estimating real sounds with an oath of secrecy in relation to guide him .\n",
      "with him romnod , and their eyes , have been a superstitious <UNK> <UNK> <UNK> tan escondida query no te <UNK> '' , and his flight , sailing on the banks of the second , whether he had heard before ; strains which must have come thus far i had with me his aid to <UNK> <UNK> under the bed , passed much of a hundred is too limited in its extent , with his mathematics with the greatest delight to the past , for they come out of sight , withered and fell violently on my career , paused ; the terrible old man was sir thomas more a very severe upon `` oppodeldoc , '' said a fat little gentleman with a pipe in his course as an object usually not frivolous , imperceptibly loses sight of that of the gods that he was , he descended the tower and commenced to talk about it ? ''\n",
      "he was deep ; you must not disturb him .\n",
      "found the casket 's lid , dragging out and above all , but received no less than ten minutes upon the mould .\n",
      "that the moon had risen mechanically my knees , covering my face .\n",
      "wearied at heart a lover of <UNK> fear .\n",
      "winter was hailed by the impulses of the wanton , much loved friend ; he soon saw enough i knew that the sea of roofs to be the case is most probably represent the word 'degree , ' 'diable , ' for october is out at last , to include , in a gentleman on shore two days after we came to speak of a radiant form rise from the world to dwell upon some more decided act of the variety of pattern for , as i am as positive that yesterday was sunday thus , with a round oath , professor rub a dub , and so worthy of his discussion with the microscope or crucible , have received one or two , thus , with almost a public school .\n",
      "i could not find matter of little moment ; and here i heard them not at least two of the sixteenth of an icy chill ran through several feet of the violet , ere a reply .\n",
      "medical aid was less <UNK> together , and of still stranger messages yet to my <UNK> for firmness sufficient to startle the whole of the young hyacinth .\n",
      "i can not tell me something about it .\n",
      "from the world as wilbur was a bond <UNK> .\n",
      "having done so , i at length here after ; she stepped from one who fled frantically out of which i could seize him ; he was unfit to return to you a conception of the sudden <UNK> of companionship and applause .\n",
      "in an old book stall , in common with their proper buttons .\n",
      "the artificial style of gardening , a new scene of the question , when he approached the arch of the volumes i have said that an advantageous offer of private possession were thrown down , so far evinced not the faces of men , '' ran the text represented an artificial alphabet , notwithstanding all the information it could not find a local door which the next thing that had laid her fair cheek upon his knees in the place , the fourth story were of glazed brick and wood , and that he had lost them both without firing the one , that his long and strange , complicated , but these were notorious , although certainly done to the town ; and no cold eye meet mine to check the impending doom , to take the hint , i possess no distinct and furious whiffs from his arms being fastened in a writing desk were still .\n",
      "she regarded with suspicion .\n",
      "the color which spoke of ? or that mental or physical symptom .\n",
      "meantime , the nearest gaol ; where violent sorrow seems a deficiency of observation on the bleak mountain wind , and the doctor administered something to say how much of <UNK> , ' 'diable , ' could refer only to be beautiful as her tears , sit in a voice excited and tense with some probability of a cloudy height beyond the small , regular , exchange , and cruelty of the faulty , and the inconvenience of the members of `` catching one 's breath , and took possession of a classic youth came to remove all participants in his knowledge been publicly worn ; though i knew that sound , too , the treasure been beneath the hole , and took from a wealthy merchant of this imprudence , she began to moan now , if one wiser , better , far above the spheres meet .\n",
      "he had heard , but the general character of the town , and found the dromedary men in england as their condition might have been solemn and affecting even to grotesqueness ; thin with the high , <UNK> that perched upon the world , not indeed exactly as <UNK> in the bishop 's cows had been <UNK> <UNK> tan escondida , que no te <UNK> <UNK> yxur <UNK> in palpably liquorish accents an effusion of eighteenth century ; but in the castle .\n"
     ]
    }
   ],
   "source": [
    "#Printing the Nueral net generated sentences\n",
    "file_path = 'spooky_vanilla_3_word.txt'\n",
    "line_count = 0\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Display only 20 lines\n",
    "        if line_count < 20:\n",
    "            print(line.strip())  # strip() removes newline characters\n",
    "            line_count += 1\n",
    "        else:\n",
    "            break  # Stop reading after 20 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Name: Aadhi Aadhavan\n",
    "\n",
    "1)Neural LM Sentence are more gramatical\n",
    "\n",
    "2)Vanilla n-gram make more sense in meaning\n",
    "\n",
    "3)I prefer the neural LM sentences\n",
    "\n",
    "Name: Valli meena \n",
    "\n",
    "1)Vanilla N-Gram Sentence are more gramatical\n",
    "\n",
    "2)Vanilla n-gram make more sense in meaning\n",
    "\n",
    "3)I prefer the Vanilla LM sentences\n",
    "\n",
    "Name: Vasant Tholappa\n",
    "\n",
    "1)Vanila N-Gram Sentence are more gramatical\n",
    "\n",
    "2)Neural LM make more sense in meaning\n",
    "\n",
    "3)I prefer the neural LM sentences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+1 - Nueral, -1 : Vanilla \n",
    "\n",
    "| Respondent | Grammaticality | Semantic Sense | Preference |\n",
    "|------------|----------------|-----------------|------------|\n",
    "| Aadhi      | +1             | -1              | +1         |\n",
    "| Valli      | -1             | +1              | -1         |\n",
    "| Vasant     | -1             | +1              | +1         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grammaticality Preference (%): (2 / 3) * 100 = 66.67%\n",
    "\n",
    "Semantic Sense Preference (%): (1 / 3) * 100 = 33.33%\n",
    "\n",
    "Overall Preference (%): (2 / 3) * 100 = 66.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: krippendorff in /Users/harisha/anaconda3/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /Users/harisha/anaconda3/lib/python3.10/site-packages (from krippendorff) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammaticality Alpha: 0.0\n",
      "Semantic Alpha: 0.0\n",
      "Overall Alpha: 0.0\n"
     ]
    }
   ],
   "source": [
    "# your imports here\n",
    "\n",
    "import krippendorff\n",
    "from krippendorff import alpha\n",
    "\n",
    "# Replace these lists with your survey responses\n",
    "grammaticality_responses = [1, 0, 0]  # 1 for neural, 0 for vanilla\n",
    "semantic_responses = [0, 1, 1]  # 1 for neural, 0 for vanilla\n",
    "overall_responses = [1, 0, 1]  # 1 for neural, 0 for vanilla\n",
    "\n",
    "# Calculate Krippendorff's alpha\n",
    "grammaticality_alpha = alpha(reliability_data=grammaticality_responses)\n",
    "semantic_alpha = alpha(reliability_data=semantic_responses)\n",
    "overall_alpha = alpha(reliability_data=overall_responses)\n",
    "\n",
    "print(\"Grammaticality Alpha:\", grammaticality_alpha)\n",
    "print(\"Semantic Alpha:\", semantic_alpha)\n",
    "print(\"Overall Alpha:\", overall_alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wordembeddings_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05041e657fa0436a83611a3d2d345b99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cd0685004814c0d974a1d809e0e2b4f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b0dca775977048f38841afae3d906eb6",
      "value": "100%"
     }
    },
    "140057e9712f46af9ebf5825ef9b1390": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05041e657fa0436a83611a3d2d345b99",
       "IPY_MODEL_a818afa6bb4f43c8b7e32a3c04f17211",
       "IPY_MODEL_72a47718e310461fbd61b312f7bf7cfe"
      ],
      "layout": "IPY_MODEL_488b55855d4d4ffc8af6d3d77aa3fdf8"
     }
    },
    "150adc7de7f54d63a215482e6a977067": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b93060412f54083b6dd7b9203ae55d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cd0685004814c0d974a1d809e0e2b4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488b55855d4d4ffc8af6d3d77aa3fdf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72a47718e310461fbd61b312f7bf7cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d9e5b3a1e144e6b34a55ab5cbce43f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_150adc7de7f54d63a215482e6a977067",
      "value": " 19579/19579 [00:00&lt;00:00, 18295.70it/s]"
     }
    },
    "843343b9adc84d949f839d51814d55aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d9e5b3a1e144e6b34a55ab5cbce43f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a818afa6bb4f43c8b7e32a3c04f17211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b93060412f54083b6dd7b9203ae55d0",
      "max": 19579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_843343b9adc84d949f839d51814d55aa",
      "value": 19579
     }
    },
    "b0dca775977048f38841afae3d906eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
